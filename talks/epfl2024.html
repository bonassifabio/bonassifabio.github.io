<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Talk @ EPFL, May 31st, 2024 | Bonassi Fabio </title> <meta name="author" content="Fabio Bonassi"> <meta name="description" content="Some useful resources"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%95&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="/talks/epfl2024"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script src="https://tarptaeya.github.io/repo-card/repo-card.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Bonassi Fabio </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd-thesis/">PhD thesis </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Talk @ EPFL, May 31st, 2024</h1> <p class="post-description">Some useful resources</p> </header> <article> <p>Welcome to the seminar! Below you can find information about the seminar, links to github repositories, and the list of publications mentioned during the presentation.</p> <h2 id="information">Information</h2> <ul> <li>Where: EPFL, Lausanne, <a href="https://plan.epfl.ch/?room==ME%20C2%20405" rel="external nofollow noopener" target="_blank">ME C2 405</a> </li> <li>When: May 31, 2024, from 11:00 to 12:00</li> <li>Speaker: <a href="/index.html">Fabio Bonassi</a> </li> </ul> <h2 id="repositories">Repositories</h2> <div class="repo-card" data-repo="bonassifabio/ssnet"></div> <p><br></p> <div class="repo-card" data-repo="bonassifabio/SSM-sysid"></div> <p><br></p> </article> <h2>Selected references</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IFAC</abbr> </div> <div id="bonassi2024structured" class="col-sm-8"> <div class="title">Structured state-space models are deep Wiener models</div> <div class="author"> <em>Fabio Bonassi</em>, Carl Andersson , Per Mattsson , and Thomas B Schön </div> <div class="periodical"> <em>In 20th IFAC Symposium on System Identification (SYSID)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2312.06211" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S2405896324013168" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The goal of this paper is to provide a system identification-friendly introduction to the Structured State-space Models (SSMs). These models have become recently popular in the machine learning community since, owing to their parallelizability, they can be efficiently and scalably trained to tackle extremely-long sequence classification and regression problems. Interestingly, SSMs appear as an effective way to learn deep Wiener models, which allows to reframe SSMs as an extension of a model class commonly used in system identification. In order to stimulate a fruitful exchange of ideas between the machine learning and system identification communities, we deem it useful to summarize the recent contributions on the topic in a structured and accessible form. At last, we highlight future research directions for which this community could provide impactful contributions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bonassi2024structured</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Structured state-space models are deep Wiener models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{20th IFAC Symposium on System Identification (SYSID)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonassi, Fabio and Andersson, Carl and Mattsson, Per and Sch{\"o}n, Thomas B}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.ifacol.2024.08.536}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">AUT</abbr> </div> <div id="bonassi2024nonlinear" class="col-sm-8"> <div class="title">Nonlinear MPC design for incrementally ISS systems with application to GRU networks</div> <div class="author"> <em>Fabio Bonassi</em>, Alessio La Bella , Marcello Farina , and Riccardo Scattolini </div> <div class="periodical"> <em>Automatica</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2309.16428" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0005109823005484" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This brief addresses the design of a Nonlinear Model Predictive Control (NMPC) strategy for exponentially incremental Input-to-State Stable (ISS) systems. In particular, a novel formulation is devised, which does not necessitate the onerous computation of terminal ingredients, but rather relies on the explicit definition of a minimum prediction horizon ensuring closed-loop stability. The designed methodology is particularly suited for the control of systems learned by Recurrent Neural Networks (RNNs), which are known for their enhanced modeling capabilities and for which the incremental ISS properties can be studied thanks to simple algebraic conditions. The approach is applied to Gated Recurrent Unit (GRU) networks, providing also a method for the design of a tailored state observer with convergence guarantees. The resulting control architecture is tested on a benchmark system, demonstrating its good control performances and efficient applicability.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bonassi2024nonlinear</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nonlinear MPC design for incrementally ISS systems with application to GRU networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonassi, Fabio and {La Bella}, Alessio and Farina, Marcello and Scattolini, Riccardo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Automatica}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{159}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{111381}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0005-1098}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.automatica.2023.111381}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">TASE</abbr> </div> <div id="xie2022robust" class="col-sm-8"> <div class="title">Learning Control Affine Neural NARX Models for Internal Model Control Design</div> <div class="author"> Jing Xie , <em>Fabio Bonassi</em>, and Riccardo Scattolini </div> <div class="periodical"> <em>IEEE Transactions on Automation Science and Engineering</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.05607" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/TASE.2024.3479321" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This paper explores the use of Control Affine Neural Nonlinear AutoRegressive eXogenous (CA-NNARX) models for nonlinear system identification and model-based control design. The idea behind this architecture is to match the known control-affine structure of the system to achieve improved performance. Coherently with recent literature of neural networks for data-driven control, we first analyze the stability properties of CA-NNARX models, devising sufficient conditions for their incremental Input-to-State Stability (δISS) that can be enforced at the model training stage. The model’s stability property is then leveraged to design a stable Internal Model Control (IMC) architecture. The proposed control scheme is tested on a real Quadruple Tank benchmark system to address the output reference tracking problem. The results achieved show that (i) the modeling accuracy of CA-NNARX is superior to the one of a standard NNARX model for given weight size and training epochs, (ii) the proposed IMC law provides performance comparable to the ones of a standard Model Predictive Controller (MPC) at a significantly lower computational burden, and (iii) the δISS of the model is beneficial to the closed-loop performance. Note to Practitioners —Many engineering systems, such as robotic manipulators and chemical reactors, are described by Control Affine (CA) models, characterized by onlinear dynamics where the control variable enters in a linear way. If only this structural information is available without any additional knowledge, for instance on the order of the system or on the value of its parameters, a black-box identification approach can be followed to estimate the model from data. For these reasons, in this paper we propose a modeling and control design method suited for this class of systems. Specifically, we assume that the system is described by a CA-Neural Nonlinear AutoRegressive eXogenous (CA-NNARX) model. Then, the estimated model is used to design a stable Internal Model Control (IMC) scheme for the solution of output reference tracking problems. The stability, performance, and robustness properties of the proposed approach are studied and tested in the control of a laboratory system. In addition, a simulation analysis shows how IMC represents a valid alternative to the popular Model Predictive Control (MPC) approach, in particular for embedded systems, where the computation power required by MPC can be too high.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xie2022robust</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Control Affine Neural NARX Models for Internal Model Control Design}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Jing and Bonassi, Fabio and Scattolini, Riccardo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Automation Science and Engineering}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TASE.2024.3479321}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">PhD</abbr> </div> <div id="bonassi2023reconciling" class="col-sm-8"> <div class="title">Reconciling deep learning and control theory: recurrent neural networks for model-based control design</div> <div class="author"> <em>Fabio Bonassi</em> </div> <div class="periodical"> Feb 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Chorafas Prize</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.politesi.polimi.it/handle/10589/196384" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Dimitris N. Chorafas Ph.D. Award from the Dimitris N. Chorafas Foundation (Switzerland) to the best Ph.D. theses for their high potential for practical application and the special significance attached to their aftermath</p> </div> <div class="abstract hidden"> <p>This doctoral thesis aims to establish a theoretically-sound framework for the adoption of Recurrent Neural Network (RNN) models in the context of nonlinear system identification and model-based control design. The idea, long advocated by practitioners, of exploiting the remarkable modeling performances of RNNs to learn black-box models of unknown nonlinear systems, and then using such models to synthesize model-based control laws, has already shown considerable potential in many practical applications. On the other hand, the adoption of these architectures by the control systems community has been so far limited, mainly because the generality of these architectures makes it difficult to attain general properties and to build solid theoretical foundations for their safe and profitable use for control design. To address these gaps, we first provide a control engineer-friendly description of the most common RNN architectures, i.e., Neural NARXs (NNARXs), Gated Recurrent Units (GRUs), and Long Short-Term Memory networks (LSTMs), as well as their training procedure. The stability properties of these architectures are then analyzed, using common nonlinear systems’ stability notions such as the Input-to-State Stability (ISS), the Input-to-State Practical Stability (ISPS), and the Incremental Input-to-State Stability (δISS). In particular, sufficient conditions for these properties are devised for the considered RNN architectures, and it is shown how to enforce these conditions during the training procedure, in order to learn provenly stable RNN models. Model-based control strategies are then synthesized for these models. In particular, nonlinear model predictive control schemes are first designed: in this context, the model’s δISS is shown to enable the attainment of nominal closed-loop stability and, under a suitable design of the control scheme, also robust asymptotic zero-error output regulation. Then, an alternative computationally-lightweight control scheme, based on the internal model control strategy, is proposed, and its closed-loop properties are discussed. The performances of these control schemes are tested on several nonlinear benchmark systems, demonstrating the potentiality of the proposed framework. Finally, some fundamental issues for the practical implementation of RNN-based control strategies are mentioned. In particular, we discuss the need for the safety verification of RNN models and their adaptation in front of changes of the plant’s behavior, the definition of RNN structures that exploit qualitative physical knowledge of the system to boost the performances and interpretability of these models, and the problem of designing control schemes that are robust to the unavoidable plant-model mismatch.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">bonassi2023reconciling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reconciling deep learning and control theory: recurrent neural networks for model-based control design}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonassi, Fabio}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Milan, Italy}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Politecnico di Milano}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{PhD thesis}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">JPC</abbr> </div> <div id="bonassi2022survey" class="col-sm-8"> <div class="title">On Recurrent Neural Networks for learning-based control: recent results and ideas for future developments</div> <div class="author"> <em>Fabio Bonassi</em>, Marcello Farina , Jing Xie , and Riccardo Scattolini </div> <div class="periodical"> <em>Journal of Process Control</em>, Feb 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2111.13557" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.jprocont.2022.04.011" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This paper aims to discuss and analyze the potentialities of Recurrent Neural Networks (RNN) in control design applications. The main families of RNN are considered, namely Neural Nonlinear AutoRegressive eXogenous, Echo State Networks, Long Short Term Memory, and Gated Recurrent Units. The goal is twofold. Firstly, to survey recent results concerning the training of RNN that enjoy Input-to-State Stability (ISS) and Incremental Input-to-State Stability (𝛿ISS) guarantees. Secondly, to discuss the issues that still hinder the widespread use of RNN for control, namely their robustness, verifiability, and interpretability. The former properties are related to the so-called generalization capabilities of the networks, i.e. their consistency with the underlying real plants, even in presence of unseen or perturbed input trajectories. The latter is instead related to the possibility of providing a clear formal connection between the RNN model and the plant. In this context, we illustrate how ISS and 𝛿ISS represent a significant step towards the robustness and verifiability of the RNN models, while the requirement of interpretability paves the way to the use of physics-based networks. The design of model predictive controllers with RNN as plant’s model is also briefly discussed. Lastly, some of the main topics of the paper are illustrated on a simulated chemical system.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bonassi2022survey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On Recurrent Neural Networks for learning-based control: recent results and ideas for future developments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonassi, Fabio and Farina, Marcello and Xie, Jing and Scattolini, Riccardo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Process Control}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{114}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{92-104}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0959-1524}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jprocont.2022.04.011}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">SCL</abbr> </div> <div id="bonassi2020stability" class="col-sm-8"> <div class="title">On the stability properties of Gated Recurrent Units neural networks</div> <div class="author"> <em>Fabio Bonassi</em>, Marcello Farina , and Riccardo Scattolini </div> <div class="periodical"> <em>System &amp; Control Letters</em>, Feb 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2011.06806" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0167691121001791" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The goal of this paper is to provide sufficient conditions for guaranteeing the Input-to-State Stability (ISS) and the Incremental Input-to-State Stability (δISS) of Gated Recurrent Units (GRUs) neural networks. These conditions, devised for both single-layer and multi-layer architectures, consist of nonlinear inequalities on network’s weights. They can be employed to check the stability of trained networks, or can be enforced as constraints during the training procedure of a GRU. The resulting training procedure is tested on a Quadruple Tank nonlinear benchmark system, showing satisfactory modeling performances.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bonassi2020stability</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the stability properties of Gated Recurrent Units neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonassi, Fabio and Farina, Marcello and Scattolini, Riccardo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{System \&amp; Control Letters}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{157}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{105049}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0167-6911}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.sysconle.2021.105049}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IFAC</abbr> </div> <div id="bonassi2021nnarx" class="col-sm-8"> <div class="title">Stability of discrete-time feed-forward neural networks in NARX configuration</div> <div class="author"> <em>Fabio Bonassi</em>, Marcello Farina , and Riccardo Scattolini </div> <div class="periodical"> <em>In 19th IFAC Symposium on System Identification (SYSID)</em> , Feb 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">IFAC Award</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2012.03741" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S2405896321011915" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>IFAC Best Student Paper Award at SYSID 2021</p> </div> <div class="abstract hidden"> <p>The idea of using Feed-Forward Neural Networks (FFNNs) as regression functions for Nonlinear AutoRegressive eXogenous (NARX) models, leading to models herein named Neural NARXs (NNARXs), has been quite popular in the early days of machine learning applied to nonlinear system identification, owing to their simple structure and ease of application to control design. Nonetheless, few theoretical results are available concerning the stability properties of these models. In this paper we address this problem, providing a sufficient condition under which NNARX models are guaranteed to enjoy the Input-to-State Stability (ISS) and the Incremental Input-to-State Stability (δISS) properties. This condition, which is an inequality on the weights of the underlying FFNN, can be enforced during the training procedure to ensure the stability of the model. The proposed model, along with this stability condition, are tested on the pH neutralization process benchmark, showing satisfactory results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bonassi2021nnarx</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Stability of discrete-time feed-forward neural networks in NARX configuration}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{54}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{547-552}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{19th IFAC Symposium on System Identification (SYSID)}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2405-8963}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.ifacol.2021.08.417}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonassi, Fabio and Farina, Marcello and Scattolini, Riccardo}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Neural networks, Nonlinear System Identification, Identification for Control, Input-to-State Stability, Incremental Input-to-State Stability}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Fabio Bonassi. Last updated: November 15, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>